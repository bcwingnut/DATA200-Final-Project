{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GradProject_NB1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"7aqCvNSwm7ug"},"source":["<h1> DS200A Computer Vision Assignment</h1>"]},{"cell_type":"markdown","metadata":{"id":"Y3MpiRZ5m7uk"},"source":["<h2>  Part One: Data Input </h2>\t\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LkklAf3DnDV7","executionInfo":{"status":"ok","timestamp":1607318009367,"user_tz":480,"elapsed":27391,"user":{"displayName":"Cem Koc","photoUrl":"","userId":"08689183003736708291"}},"outputId":"060ce185-e6a2-482b-a6ea-cda55a7dfa40"},"source":["# Mount Google Drive when working on Google Colab\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    %cd \"/content/drive/My Drive/computer_vision\"\n","    %pwd\n","    %ls\n","except:\n","    pass"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/My Drive/computer_vision\n"," \u001b[0m\u001b[01;34m20_categories_training\u001b[0m/    X_training_bovw_c150.pkl\n"," \u001b[01;34m20_Validation\u001b[0m/             X_training_bovw_c250.pkl\n"," bovw_vectorizer.pkl        X_training_bovw_c50.pkl\n"," \u001b[01;34mcifar\u001b[0m/                     X_training_bovw_c64.pkl\n"," \u001b[01;34mfigures\u001b[0m/                   X_training_bovw_c791.pkl\n"," GradProject_NB1.ipynb      X_training_combined.pkl\n"," GradProject_NB2.ipynb      X_training.pkl\n"," GradProject_NB3.ipynb      X_train_tensor.pt\n"," GradProject_NB4.ipynb      X_train_tensor_standardized.pt\n"," \u001b[01;34mimagenet20\u001b[0m/                X_unlabeled.pkl\n"," model_utils.py             Y_nn_test.pkl\n"," prediction.csv             Y_nn_train.pkl\n","'Project Narrative.ipynb'   Y_testing_bovw_c150.pkl\n"," \u001b[01;34m__pycache__\u001b[0m/               Y_testing_bovw_c250.pkl\n"," \u001b[01;34mresults\u001b[0m/                   Y_testing_bovw_c50.pkl\n"," testing_data.pkl           Y_testing_bovw_c64.pkl\n"," training_data.pkl          Y_testing_bovw_c791.pkl\n"," unlabeled_data.pkl         Y_testing_combined.pkl\n"," X_nn_test.pkl              Y_testing.pkl\n"," X_nn_train.pkl             Y_test_tensor.pt\n"," X_testing_bovw_c150.pkl    Y_training_bovw_c150.pkl\n"," X_testing_bovw_c250.pkl    Y_training_bovw_c250.pkl\n"," X_testing_bovw_c50.pkl     Y_training_bovw_c50.pkl\n"," X_testing_bovw_c64.pkl     Y_training_bovw_c64.pkl\n"," X_testing_bovw_c791.pkl    Y_training_bovw_c791.pkl\n"," X_testing_combined.pkl     Y_training_combined.pkl\n"," X_testing.pkl              Y_training.pkl\n"," X_test_tensor.pt           Y_train_tensor.pt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u2R7xonvm7uk"},"source":["<h3>  Import Statements </h3>\t\n"]},{"cell_type":"code","metadata":{"id":"HxKneVSBm7ul"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import matplotlib\n","import skimage\n","from skimage import data\n","from skimage import io\n","import re\n","import os\n","from sklearn.model_selection import train_test_split\n","\n","%config InlineBackend.figure_format = 'retina'\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5MNGfgXWoNg2"},"source":["<h2>Read Data</h2>"]},{"cell_type":"markdown","metadata":{"id":"PCeqtwBUm7us"},"source":["<h4> Take the given folder and create a dataframe with the picture object, and the encoding as listed below. </h4>\t\n","0=Airplanes, 1=Bear, 2=Blimp, 3=Comet, 4=Crab, 5=Dog, 6=Dolphin, 7=Giraffe, 8=Goat, 9=Gorilla, 10=Kangaroo, 11=Killer-Whale, 12=Leopards, 13=Llama, 14= Penguin, 15= Porcupine, 16=Teddy-Bear, 17=Triceratops, 18=Unicorn, 19=Zebra"]},{"cell_type":"markdown","metadata":{"id":"Px1xhlKVzMxJ"},"source":["We found that the encoding is the alphanumeric order of labels, which can be obtained by sorting folders with their names."]},{"cell_type":"code","metadata":{"id":"ndg4nESdm7ut"},"source":["def read_organize_training_data(file_path):\n","    legal_category_pattern = r'[a-z]+-?[a-z]+'\n","    legal_img_pattern = r'[a-z]+-?[a-z]+_{1}\\d+\\.{1}jpg'\n","\n","    pictures = []\n","    encodings = []\n","    label = 0\n","    n_grayscale_imgs = 0\n","\n","    for category_name in sorted(os.listdir(file_path)):\n","        if re.fullmatch(legal_category_pattern, category_name) and os.path.isdir(os.path.join(file_path, category_name)):\n","            print(\"category name \" + category_name + \" \" + \"label to assign: \" + str(label))\n","            category_path = os.path.join(file_path, category_name)\n","            for filename in os.listdir(category_path):\n","                if re.fullmatch(legal_img_pattern, filename) and os.path.isfile(os.path.join(category_path, filename)):\n","                    try:\n","                        filepath = os.path.join(category_path, filename)\n","                        img = io.imread(filepath)\n","                        if len(img.shape) != 3:\n","                            n_grayscale_imgs += 1\n","                            img = skimage.color.gray2rgb(img)\n","                        pictures.append(img)\n","                        encodings.append(label)\n","                    except:\n","                        print (\"Error occured while reading: \" + filepath)\n","            label += 1\n","    print(f'There are {len(pictures)-n_grayscale_imgs} RGB images, {n_grayscale_imgs} grayscale images.')\n","    return pd.DataFrame(data={'Pictures': pictures, 'Encoding': encodings})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95U4hhfnm7uv","executionInfo":{"status":"ok","timestamp":1607318620961,"user_tz":480,"elapsed":602048,"user":{"displayName":"Cem Koc","photoUrl":"","userId":"08689183003736708291"}},"outputId":"34e513cb-74c1-450a-eddf-e096b7eef130"},"source":["starting_data = read_organize_training_data(\"./20_categories_training/20_categories_training\")\n","starting_data.shape"],"execution_count":null,"outputs":[{"output_type":"stream","text":["category name airplanes label to assign: 0\n","category name bear label to assign: 1\n","category name blimp label to assign: 2\n","category name comet label to assign: 3\n","category name crab label to assign: 4\n","category name dog label to assign: 5\n","category name dolphin label to assign: 6\n","category name giraffe label to assign: 7\n","category name goat label to assign: 8\n","category name gorilla label to assign: 9\n","category name kangaroo label to assign: 10\n","category name killer-whale label to assign: 11\n","category name leopards label to assign: 12\n","category name llama label to assign: 13\n","category name penguin label to assign: 14\n","category name porcupine label to assign: 15\n","category name teddy-bear label to assign: 16\n","category name triceratops label to assign: 17\n","category name unicorn label to assign: 18\n","category name zebra label to assign: 19\n","There are 1485 RGB images, 16 grayscale images.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(1501, 2)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"tXN8JI8brwZ4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607319802919,"user_tz":480,"elapsed":4896,"user":{"displayName":"Cem Koc","photoUrl":"","userId":"08689183003736708291"}},"outputId":"581a6946-fa6d-4524-bf4a-89b9d6c1300c"},"source":["def read_organize_unlabeled_data(file_path):\n","    legal_img_pattern = r'.+.jpg'\n","\n","    pictures = []\n","    filenames = []\n","    n_grayscale_imgs = 0\n","\n","    for filename in os.listdir(file_path):\n","        if re.fullmatch(legal_img_pattern, filename) and os.path.isfile(os.path.join(file_path, filename)):\n","            try:\n","                filepath = os.path.join(file_path, filename)\n","                img = io.imread(filepath)\n","                if len(img.shape) != 3:\n","                            n_grayscale_imgs += 1\n","                            img = skimage.color.gray2rgb(img)\n","                pictures.append(img)\n","                filenames.append(filename)\n","            except:\n","                print (\"Error occured while reading: \" + filepath)\n","    print(f'There are {len(pictures)-n_grayscale_imgs} RGB images, {n_grayscale_imgs} grayscale images.')\n","    return pd.DataFrame(data={'Pictures': pictures, 'Filename': filenames})\n","unlabeled_data = read_organize_unlabeled_data(\"20_Validation\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 705 RGB images, 11 grayscale images.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jo5I49jIt5L5","executionInfo":{"status":"ok","timestamp":1607319808527,"user_tz":480,"elapsed":374,"user":{"displayName":"Cem Koc","photoUrl":"","userId":"08689183003736708291"}},"outputId":"679b270f-77ba-42e1-d1d6-2a1701756a7a"},"source":["unlabeled_data['FileID'] = unlabeled_data['Filename'].str.extract(r'validation_pic \\(([0-9]+)\\).jpg', expand=False).astype(int)\n","unlabeled_data = unlabeled_data.sort_values('FileID').reset_index().drop(columns=['FileID','index'])\n","unlabeled_data.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(716, 2)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"cOQP7aKGr_yT","executionInfo":{"status":"ok","timestamp":1607319822547,"user_tz":480,"elapsed":13046,"user":{"displayName":"Cem Koc","photoUrl":"","userId":"08689183003736708291"}},"outputId":"32fa3634-e6d2-48a7-d100-63d86cb0fed8"},"source":["unlabeled_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pictures</th>\n","      <th>Filename</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[[[80, 79, 74], [56, 55, 50], [54, 53, 48], [4...</td>\n","      <td>validation_pic (1).jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[[[10, 15, 19], [10, 15, 19], [11, 16, 19], [1...</td>\n","      <td>validation_pic (2).jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[[[232, 231, 247], [250, 249, 255], [235, 234,...</td>\n","      <td>validation_pic (3).jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[[[97, 75, 77], [98, 76, 78], [99, 77, 79], [1...</td>\n","      <td>validation_pic (4).jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[[[19, 46, 55], [19, 46, 53], [20, 47, 54], [2...</td>\n","      <td>validation_pic (5).jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            Pictures                Filename\n","0  [[[80, 79, 74], [56, 55, 50], [54, 53, 48], [4...  validation_pic (1).jpg\n","1  [[[10, 15, 19], [10, 15, 19], [11, 16, 19], [1...  validation_pic (2).jpg\n","2  [[[232, 231, 247], [250, 249, 255], [235, 234,...  validation_pic (3).jpg\n","3  [[[97, 75, 77], [98, 76, 78], [99, 77, 79], [1...  validation_pic (4).jpg\n","4  [[[19, 46, 55], [19, 46, 53], [20, 47, 54], [2...  validation_pic (5).jpg"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"WIYlqDmLm8V6"},"source":["<h2> Split and Save Data</h2>\n","\n","Because the \"20_Validation\" dataset is unlabeled, we cannot evaluate the performance of our classifiers on it. So, we split the labeled dataset to a training set and a testing set."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E7Atu1niCT7j","executionInfo":{"status":"ok","timestamp":1607319827422,"user_tz":480,"elapsed":384,"user":{"displayName":"Cem Koc","photoUrl":"","userId":"08689183003736708291"}},"outputId":"8b7fe92d-8130-4fc7-b9bd-920e3d5cb5c4"},"source":["# 80/20 split for training/testing respectively\n","training_data, testing_data = train_test_split(starting_data, test_size=0.2)\n","training_data.shape, testing_data.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1200, 2), (301, 2))"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"7CtvPBJboirT"},"source":["Store data in Pickle files. It saves memory compared to importing the whole notebook, and preserves class information compared to saving in CSV format."]},{"cell_type":"code","metadata":{"id":"YDSUYKpegp05"},"source":["training_data.to_pickle('training_data.pkl')\n","testing_data.to_pickle('testing_data.pkl')\n","unlabeled_data.to_pickle('unlabeled_data.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZPXthE_O2Olv"},"source":[""],"execution_count":null,"outputs":[]}]}